{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb1c70e-fda2-4cc8-a72e-372bd4e5e611",
   "metadata": {},
   "source": [
    "# Bayes By Backprop\n",
    "\n",
    "* [**Paper**](https://arxiv.org/abs/1505.05424)\n",
    "\n",
    "In this paper, the authors describe a method for weight regularisation which provides direct information on the uncertainty of the weights. In essence, we try to approximate the posterior $p(w | D)$ of weights $w$, given the data $D$.\n",
    "\n",
    "From Bayes' theorem, we know:\n",
    "\n",
    "$$\n",
    "p(w | D) = \\frac{p(D | w)p(w)}{p(D)}\n",
    "$$\n",
    "\n",
    "However, estimating $p(w | D)$ directly is intractible due to $p(D)$ (the evidence). So instead we can approximate $p(w | D)$ with the variational posterior $q(w | \\theta)$. The approximation can be done by selecting parameters $\\theta$ such that the Kullback-Leibler divergence between the two distributions is minimised:\n",
    "\n",
    "$$\n",
    "\\theta^* = \\text{argmin}_{\\theta} KL[q(w | \\theta) || p(w | D)]\n",
    "$$\n",
    "\n",
    "The divergence can be re-written into:\n",
    "\n",
    "$$\\begin{align}\n",
    "KL[q(w | \\theta) || p(w | D)] &= \\int q(w | \\theta) \\log \\frac{q(w | \\theta)}{p(w | D)} \\\\\n",
    "&= \\int q(w | \\theta) \\log \\frac{q(w | \\theta) p(D)}{p(D | w) p(w)} \\\\\n",
    "&= \\int q(w | \\theta) \\log \\frac{q(w | \\theta)}{p(D | w) p(w)} + \\mathbb{E}_{q(w | \\theta)}[\\log p(D)] \\\\\n",
    "&= \\int q(w | \\theta) \\log \\frac{q(w | \\theta)}{p(D | w) p(w)} + \\log p(D)\n",
    "\\end{align}$$\n",
    "\n",
    "Since $p(D)$ is constant in this expression and does not depend on $\\theta$, we can ignore it in the minimisation. This reduces the expression to:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\text{argmin}_{\\theta} KL[q(w | \\theta) || p(w | D)] &= \\text{argmin}_{\\theta} \\int q(w | \\theta) \\log \\frac{q(w | \\theta)}{p(D | w) p(w)} \\\\\n",
    "&= \\text{argmin}_{\\theta} \\int q(w | \\theta) \\log \\frac{q(w | \\theta)}{p(w)} - \\int q(w | \\theta) \\log p(D | w) \\\\\n",
    "&= \\text{argmin}_{\\theta} KL[q(w | \\theta) || p(w)] - \\mathbb{E}_{q(w | \\theta)}[\\log p(D | w)]\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7af4939c-0f1c-4fde-998c-5691d6c6e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import flax.linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860a8f9b-2b7c-46dd-8be4-d4da7470d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65eb5832-9f4a-4e8c-8e12-14f1dceb8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = jnp.array(X_train.reshape(len(X_train), -1) / 126)\n",
    "X_test = jnp.array(X_test.reshape(len(X_test), -1) / 126)\n",
    "\n",
    "y_train = jax.nn.one_hot(y_train, 10)\n",
    "y_test = jax.nn.one_hot(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572ae00c-c4e6-42c6-ba4c-17c494fe613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_sigma(n):\n",
    "    return 2 / n\n",
    "\n",
    "\n",
    "def inv_t(sigma):\n",
    "    return jnp.log(jnp.exp(sigma) - 1)\n",
    "\n",
    "\n",
    "def init_mu(shape, rng):\n",
    "    return 0.1 * jax.random.normal(rng, shape)\n",
    "\n",
    "\n",
    "def init_rho(shape, rng):\n",
    "    return inv_t(kaiming_sigma(shape[-1])) + 0.1 * jax.random.normal(rng, shape)\n",
    "\n",
    "\n",
    "def init_theta(shape, rng):\n",
    "    a, b = jax.random.split(rng)\n",
    "    return (init_mu(shape, a), init_rho(shape, b))\n",
    "\n",
    "\n",
    "def init_Wb(shape, rng):\n",
    "    a, b = jax.random.split(rng)\n",
    "    return (init_theta(shape, a), init_theta(shape[-1:], b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c78c4a9-d2b4-462e-af88-48fb1fac58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta = Tuple[jnp.ndarray, jnp.ndarray]\n",
    "Params = Tuple[Theta, ...]\n",
    "\n",
    "\n",
    "def sample_w(mu: jnp.ndarray, rho: jnp.ndarray, rng_key: jnp.ndarray) -> jnp.ndarray:\n",
    "    eps: jnp.ndarray = jax.random.normal(rng_key, mu.shape)\n",
    "    w = mu + jnp.log(1 + jnp.exp(rho)) * eps\n",
    "    return w\n",
    "\n",
    "\n",
    "def bbb_mlp(params: Params, X: jnp.ndarray, rng_key: jnp.ndarray) -> Tuple[jnp.ndarray, Tuple[jnp.ndarray, ...]]:\n",
    "    theta_W0, theta_b0, theta_W1, theta_b1, theta_W2, theta_b2 = params\n",
    "    k0, k1, k2, k3, k4, k5 = jax.random.split(rng_key, 6)\n",
    "\n",
    "    W0 = sample_w(*theta_W0, k0)\n",
    "    b0 = sample_w(*theta_b0, k1)\n",
    "    \n",
    "    W1 = sample_w(*theta_W1, k2)\n",
    "    b1 = sample_w(*theta_b1, k3)\n",
    "    \n",
    "    W2 = sample_w(*theta_W2, k4)\n",
    "    b2 = sample_w(*theta_b2, k5)\n",
    "    return nn.relu(nn.relu(X @ W0 + b0) @ W1 + b1) @ W2 + b2, (W0, W1, W2)\n",
    "\n",
    "\n",
    "def kl_div(p: Params) -> jnp.ndarray:\n",
    "    kl = jnp.array(0)\n",
    "    \n",
    "    mu_p, sigma_p = jnp.array(0), jnp.exp(-2)\n",
    "    for (mu_q, rho_q) in p:\n",
    "        sigma_q = jnp.log(1 + jnp.exp(rho_q))\n",
    "        kl += jnp.sum(\n",
    "            2 * jnp.log(sigma_p / sigma_q)\n",
    "            - 1 + (sigma_q / sigma_p) ** 2\n",
    "            + ((mu_p - mu_q) / sigma_p) ** 2\n",
    "        )\n",
    "    return 0.5 * kl\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(\n",
    "    params: Params,\n",
    "    X: jnp.ndarray,\n",
    "    y: jnp.ndarray,\n",
    "    rng_key: jnp.ndarray,\n",
    "    n_posterior_samples: int = 10,\n",
    "    eta: float = 1e-3,\n",
    "    beta: float = 0.05,\n",
    ") -> Tuple[Params, jnp.ndarray, jnp.ndarray]:\n",
    "    def loss_fn(p: Params, k: jnp.ndarray) -> jnp.ndarray:\n",
    "        y_hat, _ = bbb_mlp(p, X, k)\n",
    "        loss = (\n",
    "            # log q(w | theta) / p(w)\n",
    "            beta * kl_div(p)\n",
    "            # log p(D | theta)\n",
    "            - jnp.mean(\n",
    "                jnp.sum(y * nn.log_softmax(y_hat, axis=-1), axis=-1)\n",
    "            )\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    G = jax.tree_map(lambda _: jnp.zeros_like(_), params)\n",
    "    f = jax.value_and_grad(loss_fn)\n",
    "    L = jnp.array(0)\n",
    "    for i in range(n_posterior_samples):\n",
    "        rng_key, key = jax.random.split(rng_key)\n",
    "        l, g = f(params, key)\n",
    "        L += l\n",
    "        G = jax.tree_map(lambda c, k: c + k, g, G)\n",
    "\n",
    "    # even though we are trying to approximate the expectation of the gradient\n",
    "    # there is no point in normalising by the number of samples, as it would be\n",
    "    # equivalent to using a lower learning rate\n",
    "    # G = jax.tree_map(lambda g: g / n_posterior_samples, G)\n",
    "    return update_params(params, G, eta=eta), L / n_posterior_samples, rng_key\n",
    "\n",
    "\n",
    "def update_params(params: Params, gradients: Params, eta: float) -> Params:\n",
    "    return jax.tree_map(lambda w, g: w - eta * g, params, gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95505b33-f5cb-4a87-9987-3902e692c48d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_batch_indices(rng: jnp.ndarray, dataset_size: int, batch_size: int) -> jnp.ndarray:\n",
    "    steps_per_epoch = dataset_size // batch_size\n",
    "\n",
    "    perms = jax.random.permutation(rng, dataset_size)\n",
    "    perms = perms[:steps_per_epoch * batch_size]  # skip incomplete batch\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    return perms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d4080d2-8d78-4d66-8765-4758d36a858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5c9cd50-2fb6-424d-bbe7-057127f41961",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = ()\n",
    "for l in [\n",
    "    (28 ** 2, 512),\n",
    "    (512, 256),\n",
    "    (256, 10),\n",
    "]:\n",
    "    p0 = p0 + init_Wb(l, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710b811d-2abb-47e0-bb9f-73b675a31830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_beta(I):\n",
    "    M = len(I)\n",
    "    for ix, i in enumerate(I, 1):\n",
    "        yield (2 ** (M - ix)) / (2 ** M - 1), i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24257728-b112-48dd-9adc-e8945c875b95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 (loss=0.982): 100%|█████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:45<00:00, 10.30it/s]\n",
      "Epoch 1 (loss=0.794): 100%|█████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.25it/s]\n",
      "Epoch 2 (loss=0.588): 100%|█████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.60it/s]\n",
      "Epoch 3 (loss=0.664): 100%|█████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.53it/s]\n",
      "Epoch 4 (loss=0.805): 100%|█████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:29<00:00, 15.65it/s]\n",
      "Epoch 5 (loss=0.755): 100%|█████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.23it/s]\n",
      "Epoch 6 (loss=0.723): 100%|█████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:29<00:00, 15.68it/s]\n",
      "Epoch 7 (loss=0.707): 100%|█████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:29<00:00, 15.67it/s]\n",
      "Epoch 8 (loss=0.754): 100%|█████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.35it/s]\n",
      "Epoch 9 (loss=0.832): 100%|█████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.56it/s]\n",
      "Epoch 10 (loss=0.792): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.56it/s]\n",
      "Epoch 11 (loss=0.679): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:31<00:00, 15.01it/s]\n",
      "Epoch 12 (loss=0.708): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.34it/s]\n",
      "Epoch 13 (loss=0.694): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.30it/s]\n",
      "Epoch 14 (loss=0.634): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:31<00:00, 14.85it/s]\n",
      "Epoch 15 (loss=0.678): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:31<00:00, 14.64it/s]\n",
      "Epoch 16 (loss=0.684): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:31<00:00, 14.88it/s]\n",
      "Epoch 17 (loss=0.749): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.29it/s]\n",
      "Epoch 18 (loss=0.734): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.24it/s]\n",
      "Epoch 19 (loss=0.779): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.37it/s]\n",
      "Epoch 20 (loss=0.612): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.41it/s]\n",
      "Epoch 21 (loss=0.599): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.57it/s]\n",
      "Epoch 22 (loss=0.762): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.52it/s]\n",
      "Epoch 23 (loss=0.728): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.48it/s]\n",
      "Epoch 24 (loss=0.683): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:32<00:00, 14.28it/s]\n",
      "Epoch 25 (loss=0.737): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:33<00:00, 13.97it/s]\n",
      "Epoch 26 (loss=0.776): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:32<00:00, 14.27it/s]\n",
      "Epoch 27 (loss=0.597): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:31<00:00, 14.92it/s]\n",
      "Epoch 28 (loss=0.777): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.29it/s]\n",
      "Epoch 29 (loss=0.709): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.41it/s]\n",
      "Epoch 30 (loss=0.693): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.49it/s]\n",
      "Epoch 31 (loss=0.686): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.34it/s]\n",
      "Epoch 32 (loss=0.658): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.39it/s]\n",
      "Epoch 33 (loss=0.760): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.35it/s]\n",
      "Epoch 34 (loss=0.683): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.43it/s]\n",
      "Epoch 35 (loss=0.538): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.41it/s]\n",
      "Epoch 36 (loss=0.633): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.31it/s]\n",
      "Epoch 37 (loss=0.691): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.39it/s]\n",
      "Epoch 38 (loss=0.663): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.39it/s]\n",
      "Epoch 39 (loss=0.831): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:31<00:00, 14.87it/s]\n",
      "Epoch 40 (loss=0.699): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.30it/s]\n",
      "Epoch 41 (loss=0.672): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:29<00:00, 15.60it/s]\n",
      "Epoch 42 (loss=0.716): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:29<00:00, 15.60it/s]\n",
      "Epoch 43 (loss=0.692): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:30<00:00, 15.39it/s]\n",
      "Epoch 44 (loss=0.841): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:32<00:00, 14.43it/s]\n",
      "Epoch 45 (loss=0.689): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:32<00:00, 14.61it/s]\n",
      "Epoch 46 (loss=0.576): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:34<00:00, 13.47it/s]\n",
      "Epoch 47 (loss=0.685): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:32<00:00, 14.29it/s]\n",
      "Epoch 48 (loss=0.688): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:31<00:00, 14.74it/s]\n",
      "Epoch 49 (loss=0.758): 100%|████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:31<00:00, 14.98it/s]\n"
     ]
    }
   ],
   "source": [
    "r = rng\n",
    "p = p0\n",
    "for e in range(50):\n",
    "    r, r0 = jax.random.split(r, 2)\n",
    "    ix = get_batch_indices(r0, len(X_train), 128)\n",
    "    I = tqdm.tqdm(ix, desc=f\"Epoch {e}\")\n",
    "    for beta, i in with_beta(I):\n",
    "        p, l, r = train_step(p, X_train[i], y_train[i], r, eta=1e-3, beta=beta)\n",
    "        I.set_description(f\"Epoch {e} (loss={l.item():.3f})\")\n",
    "        I.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31d9097f-0c9b-4e5f-9056-596ecd53b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, _ = bbb_mlp(p, X_test, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe222fc0-4fd9-4f90-bd53-7d675a437b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.90       980\n",
      "           1       0.84      0.99      0.91      1135\n",
      "           2       0.87      0.78      0.82      1032\n",
      "           3       0.74      0.87      0.80      1010\n",
      "           4       0.86      0.80      0.83       982\n",
      "           5       0.87      0.49      0.63       892\n",
      "           6       0.81      0.93      0.87       958\n",
      "           7       0.93      0.80      0.86      1028\n",
      "           8       0.74      0.74      0.74       974\n",
      "           9       0.77      0.78      0.77      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.83      0.82      0.81     10000\n",
      "weighted avg       0.83      0.82      0.82     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    metrics.classification_report(\n",
    "        y_test.argmax(axis=1),\n",
    "        y_hat.argmax(axis=1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0082edd-55ff-4f7f-bc3e-ba533500ea85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9792882105162253"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, nn.softmax(y_hat, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018789f-d330-4b97-9d36-c288770e63bb",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "\n",
    "While theoretically neat, this method is both involved in terms of setup, and seems _very_ sensitive to hyper-parameter settings and intial parameters $\\theta_{t = 0}$. It is clear that the authors of this paper have spent quite a bit of time tuning these hyper-parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a6bb7-f293-46aa-8ba0-05158e71aa95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Appendix\n",
    "\n",
    "Here I show some additional working.\n",
    "\n",
    "### KL-divergence between two univariate Gaussians\n",
    "\n",
    "We start by defining the classic KL divergence between two continuous random distributions $p(x)$ and $q(x)$:\n",
    "\n",
    "$$\n",
    "KL[p(x) || q(x)] = \\int p(x) \\log \\frac{p(x)}{q(x)}\n",
    "$$\n",
    "\n",
    "and the univariate Gaussian probability (density) function:\n",
    "\n",
    "$$\\begin{align}\n",
    "p(x) &= \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(- \\frac{z^2}{2}\\right) \\\\\n",
    "z &= \\frac{x - \\mu}{\\sigma}\n",
    "\\end{align}$$\n",
    "\n",
    "Taking the logarithm of the Gaussian:\n",
    "\n",
    "$$\n",
    "\\log p(x) = - \\frac{1}{2} \\left( \\log 2 \\pi + \\log \\sigma^2 + z^2 \\right)\n",
    "$$\n",
    "\n",
    "Expanding the logarithm, we get:\n",
    "\n",
    "$$\n",
    "KL[p(x) || q(x)] = \\int p(x) \\log p(x) - \\int p(x) \\log q(x)\n",
    "$$\n",
    "\n",
    "Let us first focus on the Shannon entropy (first term of RHS):\n",
    "\n",
    "$$\\begin{align}\n",
    "\\int p(x) \\log p(x) &= \\int - \\frac{1}{2} p(x) \\left( \\log 2 \\pi + \\log \\sigma^2 + z^2 \\right) \\\\\n",
    "&= - \\frac{1}{2} \\int p(x) \\left( \\log 2 \\pi + \\log \\sigma^2 + z^2 \\right) \\\\\n",
    "&= - \\frac{1}{2} \\left( \\log 2 \\pi + \\log \\sigma^2 + \\int p(x) z^2 \\right)\\\\\n",
    "&= - \\frac{1}{2} \\left( \\log 2 \\pi + \\log \\sigma^2 + \\mathbb{E}[z^2] \\right)\n",
    "\\end{align}$$\n",
    "\n",
    "Now, since\n",
    "$$\\begin{align}\n",
    "\\mathbb{V}[x] = \\mathbb{E}[x^2] - \\mathbb{E}[x]^2 \\iff \\mathbb{E}[x^2] = \\mathbb{V}[x] + \\mathbb{E}[x]^2\n",
    "\\end{align}$$\n",
    "\n",
    "and we know that $\\mathbb{E}[z] = 0$ and $\\mathbb{V}[z] = 1$, we hence get:\n",
    "\n",
    "$$\n",
    "\\int p(x) \\log p(x) = - \\frac{1}{2} \\left( \\log 2 \\pi + \\log \\sigma^2 + 1 \\right)\n",
    "$$\n",
    "\n",
    "Next, we focus on the cross-entropy part of the KL (second term of RHS). Here, I will start introducing subscripts, such that the distinctions between $p(x)$ and $q(x)$ (and their moments) are made clear:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\int p(x) \\log q(x) &= \\int - \\frac{1}{2} p(x) \\left( \\log 2 \\pi + \\log \\sigma_q^2 + z_q^2 \\right) \\\\\n",
    "&= - \\frac{1}{2} \\left( \\log 2 \\pi + \\log \\sigma_q^2 + \\mathbb{E}_p[z_q^2] \\right)\n",
    "\\end{align}$$\n",
    "\n",
    "Focusing just on $\\mathbb{E}_p[z_q^2]$:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_p[z_q^2] &= \\int p(x) \\left( \\frac{x - \\mu_q}{\\sigma_q} \\right)^2 \\\\\n",
    "&= \\int p(x) \\frac{x^2 - 2x\\mu_q + \\mu_q^2}{\\sigma_q^2} \\\\\n",
    "&= \\frac{1}{\\sigma_q^2} \\left( \\int p(x) x^2  - \\int p(x) 2 x \\mu_q  + \\int p(x) \\mu_q^2 \\right) \\\\\n",
    "&= \\frac{1}{\\sigma_q^2} \\left( \\mathbb{E}[x^2] - 2 \\mu_p \\mu_q + \\mu_q^2 \\right) \\\\\n",
    "&= \\frac{1}{\\sigma_q^2} \\left( \\sigma_p^2 + \\mu_p^2 - 2 \\mu_p \\mu_q + \\mu_q^2 \\right) \\\\\n",
    "&= \\frac{1}{\\sigma_q^2} \\left( \\sigma_p^2 + (\\mu_p - \\mu_q)^2 \\right) \\\\\n",
    "&= \\frac{\\sigma_p^2}{\\sigma_q^2} + \\left(\\frac{\\mu_p - \\mu_q}{\\sigma_q}\\right)^2\n",
    "\\end{align}$$\n",
    "\n",
    "Which gives us:\n",
    "\n",
    "$$\n",
    "\\int p(x) \\log q(x) = - \\frac{1}{2} \\left( \\log 2 \\pi + \\log \\sigma_q^2 + \\frac{\\sigma_p^2}{\\sigma_q^2} + \\left(\\frac{\\mu_p - \\mu_q}{\\sigma_q}\\right)^2 \\right)\n",
    "$$\n",
    "\n",
    "Now, we can combine the entropy and cross-entropy terms to get the full KL-div:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\int p(x) \\log \\frac{p(x)}{q(x)} &= - \\frac{1}{2} \\left( \\log 2 \\pi + \\log \\sigma_p^2 + 1 \\right) + \\frac{1}{2} \\left( \\log 2 \\pi + \\log \\sigma_q^2 + \\frac{\\sigma_p^2}{\\sigma_q^2} + \\left(\\frac{\\mu_p - \\mu_q}{\\sigma_q}\\right)^2 \\right) \\\\\n",
    "&= \\frac{1}{2} \\left(2 \\log \\frac{\\sigma_q}{\\sigma_p} + \\left( \\frac{\\sigma_p}{\\sigma_q} \\right)^2 + \\left(\\frac{\\mu_p - \\mu_q}{\\sigma_q}\\right)^2 - 1\\right)\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "Thus, for use-case we have:\n",
    "\n",
    "$$\n",
    "KL[q(w | \\theta) || p(w)] = \\frac{1}{2} \\left(2 \\log \\frac{\\sigma_{p(w)}}{\\sigma_{q(w | \\theta)}} + \\left( \\frac{\\sigma_{q(w | \\theta)}}{\\sigma_{p(w)}} \\right)^2 + \\left(\\frac{\\mu_{q(w | \\theta)} - \\mu_{p(w)}}{\\sigma_{p(w)}}\\right)^2 - 1\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a7975f-3fb9-4c05-ac1a-88a527731764",
   "metadata": {},
   "source": [
    "### Zero gradients\n",
    "\n",
    "Curiously, it turns out that the gradients $\\frac{\\partial L}{\\partial \\theta} = 0$, when we remove the KL-div term from the loss. The following derivation shows why.\n",
    "\n",
    "Suppose we only have a single layer with weights $\\mathbf{W}$, and a softmax output. The loss is the negative log-likelihood, and defined as:\n",
    "\n",
    "$$\\begin{align}\n",
    "L &= - \\sum_i^J y_i \\log z_i \\\\\n",
    "z_i &= \\frac{\\exp d_i}{\\sum_j^J \\exp d_j} \\\\\n",
    "d_i &= \\sum_j W_{ij} x_j \\\\\n",
    "W_{ij} &= \\mu_{ij} + \\sigma_{ij} \\epsilon_{ij}\n",
    "\\end{align}$$\n",
    "\n",
    "for datapoint $\\mathbf{x}$. Taking the derivative of $L$ w.r.t. $\\mu_{ij}$, we get:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mu_{op}} = \\frac{\\partial L}{\\partial z_i} \\frac{\\partial z_i}{\\partial d_j} \\frac{\\partial d_j}{\\partial W_{kh}} \\frac{\\partial W_{kh}}{\\partial \\mu_{op}}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\begin{align}\n",
    "\\frac{\\partial L}{\\partial z_i} &= - \\frac{y_i}{z_i} \\\\\n",
    "\\frac{\\partial z_i}{\\partial d_j} &= \\begin{cases}\n",
    "z_i (1 - z_i) \\quad \\text{if } i = j \\\\\n",
    "- z_i z_j \\quad \\text{otherwise}\n",
    "\\end{cases} \\\\\n",
    "\\frac{\\partial d_j}{\\partial W_{kh}} &= \\begin{cases}\n",
    "x_h \\quad \\text{if } j = k \\\\\n",
    "0 \\quad \\text{otherwise}\n",
    "\\end{cases} \\\\\n",
    "\\frac{\\partial W_{kh}}{\\partial \\mu_{op}} &= \\begin{cases}\n",
    "1 \\quad \\text{if } k = o \\land h = p \\\\\n",
    "0 \\quad \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{align}$$\n",
    "\n",
    "Combining these, we get\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_i}\\frac{\\partial z_i}{\\partial d_j} = \\begin{cases}\n",
    "-(1 - z_i) \\quad \\text{if } i = j \\\\\n",
    "z_j \\quad \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Note that $y_i \\in \\{0, 1\\}$, and that only ever one $y_i = 1$ (i.e. one-hot encoding). We can collect these derivatives into Jacobian $\\mathbf{Z} \\in \\mathbb{R}^{1 \\times J}$. Equally, we can define the Jacobian tensor $\\mathbf{D} \\in \\mathbb{R}^{J \\times (K  \\times H)}$ for $\\frac{\\partial d_j}{\\partial W_{kh}}$. Putting these two together, we get:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{kh}} = \\frac{\\partial L}{\\partial z_j}\\frac{\\partial z_i}{\\partial d_j}\\frac{\\partial d_j}{\\partial W_{kh}} \\implies \\mathbf{Q} = \\mathbf{Z}\\mathbf{D}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{Q} \\in \\mathbb{R}^{K \\times H}$ and\n",
    "\n",
    "$$\n",
    "\\mathbf{Q} = \\begin{bmatrix}\n",
    "z_j x_0 & \\dots & - x_0 (1 - z_i) \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "z_j x_H & \\dots & - x_H (1 - z_i)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "And then finally, we have Jacobian tensor $\\mathbf{\\Omega} \\in \\mathbb{R}^{(K \\times H) \\times (K \\times H)}$, which captures the partial derivatives $\\frac{\\partial W_{kh}}{\\partial \\mu_{op}}$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
